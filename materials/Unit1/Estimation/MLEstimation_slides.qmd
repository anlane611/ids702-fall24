---
title: "Maximum Likelihood Estimation"
format: 
  revealjs:
    incremental: true
    multiplex: true
    chalkboard: true
    html-math-method: mathjax
webr: 
  show-startup-message: false
  show-header-message: false
  home-dir: '/home/r-user/'
  packages: ['ggplot2', 'dplyr', 'FamilyRank']
filters:
  - webr
execute:
  freeze: auto
---

## Estimation Big Picture

## Maximum Likelihood Estimation

Let $X_1, X_2, ..., X_n \stackrel{iid}{\sim} F_{\theta}$

 

Then the **joint distribution** of ($X_1, ..., X_n$) is given by $f_{\theta}(x_1,...,x_n)=\prod_{i=1}^{n} f_{\theta}(x_i)$

 

Now, we define the **likelihood function** as a function of the fix population parameter $\theta$ : $L(\theta)=f_{\theta}(X_1,...,X_n)=\prod_{i=1}^nf_{\theta}(X_i)$

We want to find the value of $\theta$ that maximizes the likelihood function and call it $\hat{\theta}$

## Mechanics

1.  Assume a distribution for the population
2.  Define the likelihood: joint probability of the data
3.  Take the log of the likelihood
4.  Find the value of $\theta$ that maximizes the likelihood:
    1.  Differentiate the log-likelihood with respect to $\theta$
    2.  Set the derivative to 0
    3.  Solve for $\theta$

## Evaluating Estimators

-   Bias: Average distance from the population parameter

    -   Bias($\hat{\theta}$) = $\mathbf{E}[\hat{\theta}]-\theta$

-   Standard Error (SE): standard deviation of the estimator (i.e., SD of the sampling distribution)

    -   STD($\hat{\theta}$)= $\sqrt{\mathbf{E}[\hat{\theta}-\mathbf{E}(\hat{\theta})]^2}$

-   Mean Squared Error (MSE): combines standard error and bias

    -   MSE($\hat{\theta}$)= $\mathbf{E}[\hat{\theta}-\theta]^2$ = SE$^2$ + Bias$^2$

## Example

Let $X_1, X_2, ..., X_n \stackrel{iid}{\sim} Poisson(\lambda)$

Derive the MLE, $\hat{\lambda}$ and determine if this is an unbiased estimator of $\lambda$
